---
title: "Análisis de datos de precio y demanda de electricidad"
subtitle: "Proyecto final"
author: "Gabriel Cecconato"
date: "30/07/2024"
output:
  html_document:
    theme: cerulean
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


```{r librerias, echo=FALSE, warning=FALSE}
library(tidyverse)
library(DT)
library(ggfortify)
```


```{r Dataset, echo=FALSE, warning=FALSE}
# Cargamos el conjunto de datos a analizar
ds_edva <- read.csv("analisis-datos-precio-y-deamanda-electricidad-57335-Cecconato.csv")

```


# Acerca del conjuntos de datos

El conjunto de datos contiene el precio diario, demanda y datos meteorológicos en el segundo estado más grande de Australia. El mismo es público y fue obtenido de https://www.kaggle.com/datasets/aramacus/electricity-demand-in-victoria-australia.

Según la fuente en 2020, 6,7 millones de personas residen en Victoria, el segundo estado más poblado de Australia. La mayoría de ellos, cinco millones, viven o trabajan en Melbourne, la capital del estado. Durante 2020, Australia fue uno de los primeros en cerrar fronteras internacionales, seguido de un cierre de fronteras interestatales. Victoria introdujo algunas de las restricciones más estrictas a la actividad empresarial relacionadas con la pandemia, lo que provocó que una parte importante de su población trabajara desde casa.

En el citado conjunto de datos hay `r nrow(ds_edva)` observaciones y `r ncol(ds_edva)` variables, y su estructura es la siguiente:

```{r estrutura, echo=FALSE}
# Mostramos la estrucuctura del conjunto de datos a analizar
str(ds_edva)
```

## Descripción de las variables 

1. **date**: fecha de la observación.
2. **demand**: demanda total diaria de electricidad en MWh.
3. **RRP**: precio de venta recomendado en AUD$/MWh.
4. **demand_pos_RRP**: demanda diaria total con un **RRP** positivo en MWh.
5. **RRP_positive**:  **RRP** positivo promedio, ponderado por la demanda intradiaria correspondiente en AUD$/MWh.
6. **demand_neg_RRP**: demanda diaria total con un **RRP** negativo en MWh.
7. **RRP_negative**: **RRP** negativo promedio, ponderado por la demanda intradiaria correspondiente en AUD$/MWh.
8. **frac_at_neg_RRP**: una fracción del día en que la demanda se negoció a un **RRP** negativo.
9. **min_temperature**: temperatura mínima durante el día en grados Celsius.
10. **max_temperature**: temperatura máxima durante el día en grados Celsius.
11. **solar_exposure** : energía solar diaria total en MJ/m^2^.
12. **rainfall**: precipitación diaria en mm.
13. **school_day**: si los estudiantes estaban en la escuela ese día (Y=sí, N=no).
14. **holiday**: si el día era feriado estatal o nacional (Y=sí, N=no).

```{r crear una copia, echo=FALSE}
# Creamos una copia del conjunto de datos
ds_edva_copy <- ds_edva
```

## Modificación de tipos de datos 

Convertimos los tipos de datos de algunas variables del conjunto de datos. La variable **date** al tipo *Date* (fecha) y las variables **school_day** y **holiday** al tipo *Factor* (categórica). Así la estructura de datos queda:

```{r convertir de character a fecha o factor, echo=FALSE}
# Convertimos algunos tipos de variables
ds_edva_copy <- ds_edva_copy %>%
  mutate(date = as.Date(date),
         across(.cols = c(school_day, holiday), .fns = factor))
str(ds_edva_copy)
```

## Datos faltantes

Analizamos el conjunto de datos y encontramos `r sum(is.na(ds_edva_copy))` datos faltantes con la siguiente desagregación por variable:


```{r Data faltantes, echo=FALSE, warning=FALSE}
# Contamos datos faltantes por variable
missing_values <- colSums(is.na(ds_edva_copy))

# Mostramos la cantidad de datos faltantes por variable
print(missing_values)
```

Se observa que los datos faltantes son relativamente pocos. Sólo hay datos faltantes en las variables **solar_exposure** (1 observación) y **rainfall** (3 observaciones). Por la cuantía relativa podría optarse por descartar tales observaciones, no obstante ya que en total son `r nrow(ds_edva)` observaciones y a los fines didácticos se realizará la imputación de los datos faltantes con su respectiva mediana.

```{r mediana_edad, echo=TRUE}
# Imputación de los datos faltantes con su respectiva mediana
ds_edva_copy <- ds_edva_copy %>%
  mutate(solar_exposure = 
         replace_na(solar_exposure, median(solar_exposure, na.rm = TRUE)),
         rainfall = 
         replace_na(rainfall, median(rainfall, na.rm = TRUE)),
         )  
```

# Resumen de datos

Presentamos un resumen del conjunto de datos con métricas relevantes por cada variable. Y debido a la imputación de los datos faltantes ya implementada, no se observan datos faltantes para ninguna de las variables.  

```{r Summary, echo=FALSE, warning=FALSE}
# Hacemos un summary, con lapply que sale en formato de lista y se lee mejor
lapply(ds_edva_copy,summary)
```

# Análisis de relaciones entre variables

Presentamos a continuación un gráfico de líneas suavizadas con intervalos de confianza sombreados donde en el eje horizontal están los meses de la fecha (variable **date**), en el eje vertical la demanda total diaria de electricidad en MWh (variable **demand**) y cada año de la citada fecha diferenciado por distintos colores. 

Como se puede apreciar hay una estacionalidad marcada en la demanda registando picos en los los meses de invierno y de verano (y valles en las estaciones de transición, primavera y otoño). En particular se puede observar que hay una caída de la demanda para el año 2020 (no obstante, el abrupto declive hacia los meses finales se debe a que el conjunto de datos posee observaciones de fecha hasta el 06/10/2020).

```{r gráfico de líneas suavizadas,echo=FALSE, warning=FALSE}
# Creamos una variable nueva como factor en base al año de la fecha
ds_edva_copy <- ds_edva_copy %>%
  mutate(year = as.factor(year(date)))

# Ggraficamos demanda con límites en el eje x para el mes considerando los 12 meses del año 
# abiertos por trimestre
ggplot(data = ds_edva_copy) +
  geom_smooth(mapping = aes(x=month(date), y=demand, color= year)) +
  ylab("Demanda")+ # eje y
  scale_x_continuous(name = "Mes", limits = c(1, 12), breaks = seq(0, 12, by = 3)) +
  labs(title = "Demanda por mes en cada año")
```

Por otro lado si relacionamos demanda con fechas de día feriado (**holiday**) y luego con día escolar (**school_day**), podemos observar una demanda sensiblemente mayor en días que no son feriados, y para el caso de día escolar si bien también es mayor relativamente lo es en menor medida. 

```{r boxplots demanda y factores,echo=FALSE, warning=FALSE}
ggplot(ds_edva_copy) + 
  geom_boxplot(aes(x=holiday, y=demand)) + 
  coord_flip()+
  labs(title = "Relación entre día feriado y demanda",
       y = "Demanda",
       x = "Día feriado")

ggplot(ds_edva_copy) + 
  geom_boxplot(aes(x=school_day, y=demand)) + 
  coord_flip()+
  labs(title = "Relación entre día escolar y demanda",
       y = "Demanda",
       x = "Día escolar")
```

A continuación presentamos la relación entre la Demanda total diaria de electricidad en MWh  (**demand**) y el precio de venta recomendado (**RRP**) donde observamos que para valores relativamente altos de demanda el precio aumenta considerablemente. Al observar un aumento sensible del mismo a partir de aproximadamente a 150000 MWh, adjuntamos luego un gráfico complementario filtrado.

```{r demanda y RRP,echo=FALSE, warning=FALSE}
# Relación entre demanda y precio
ggplot(data = ds_edva_copy, aes(x = demand, y = RRP)) +
  geom_point() +
  geom_smooth(se=FALSE) +
  labs(title = "Relación entre demanda y precio",
       x = "Demanda total diaria de electricidad en MWh",
       y = "Precio de venta recomendado")
# Relación entre demanda y precio, filrtado para demanda < 150000 MWh
ggplot(data = filter(ds_edva_copy, demand < 150000), aes(x = demand, y = RRP)) +
  geom_point() +  
  geom_smooth() +
  labs(title = "Relación entre demanda y precio para demanda < 150000 MWh",
       x = "Demanda total diaria de electricidad en MWh",
       y = "Precio de venta recomendado")
```

También parece interesante obsevar el comportamiento de la Demanda total diaria de electricidad en MWh (**demand**) y las temperaturas mínimas y máximas observadas durante cada día (**min_temperature** y  **max_temperature**). Visualizamos con puntos de distinto color las zonas de temperaturas máximas y mínimas y cómo la demanda tiende a incrementar con temperaturas extremas.

```{r demanda y temperaturas,echo=FALSE, warning=FALSE}
# Creamos un nuevo conjunto de datos para el gráfico
data_long <- ds_edva_copy %>%
  pivot_longer(cols = c(max_temperature, min_temperature), 
               names_to = "tipo_temperatura", 
               values_to = "temperatura")

# Generamos el gráfico con etiquetas y colores
ggplot(data = data_long) + 
  geom_point(mapping = aes(x = temperatura, y = demand, color = tipo_temperatura)) + 
  scale_color_manual(values = c("max_temperature" = "red", "min_temperature" = "blue")) +
  geom_smooth(se=F,aes(x = temperatura, y = demand), color="black") +
  labs(title = "Relación entre Demanda y Temperatura",
       x = "Temperatura durante el día en grados Celsius",
       y = "Demanda total diaria de electricidad en MWh",
       color = "Tipo de Temperatura") +
  theme_minimal()
```

Finalmente nos pareció relevante cotejar la Demanda total diaria de electricidad en MWh con la precipitación diaria en mm (variable **rainfall**). La correlación entre ambas variables resulta de `r cor(ds_edva_copy$demand, ds_edva_copy$max_temperature)`; valor negativo, algo esperado por la gráfica, aunque claramente muy cercano a cero lo que significa que casi no hay correlación lineal entre estas variables.

```{r demanda y rainfall,echo=FALSE, warning=FALSE}
# Graficamos relación entre demanda y precipitación diaria
ggplot(data = ds_edva_copy, aes(x = rainfall, y = demand)) +
  geom_point() +
  geom_smooth(se=FALSE) +
  labs(title = "Relación entre demanda y precipitación diaria en mm",
       x = "Precipitación diaria en mm",
       y = "Demanda total diaria de electricidad en MWh")
```

# Análisis de los componentes principales

El análisis de los componentes principales (*PCA, Principal Component Analysis*) es un método estadístico que utiliza autovalores y autovectores para convertir los conjuntos de observaciones a un conjunto de variables linealmente no correlacionadas, denominadas como **componentes principales**.

Se realiza para tomar un conjunto de datos de muchas dimensiones y reducir las mismas a un número más manejable, extraer las variables más importantes y encontrar aquellas que logran explicar la máxima variación en el conjunto de datos.

## Acondicionamiento del conjunto de datos

Para implementar el **PCA** el conjunto de datos debe cumplir con los siguientes requisitos:

* Que todas las variables de las observaciones sean numéricas. 
* Y que no haya datos faltantes.

Dado que el conjunto de datos ya fue tratado previamente, validamos que los datos faltantes son: `r sum(is.na(ds_edva_copy))`. Por lo tanto se proseguirá con su acondicioamiento para que todas las variables de las observaciones sean numéricas.

Convertimos los tipos de datos de algunas variables del conjunto de datos, puesto que las variables **date**,  **school_day** y **holiday** no son numéricas. 

* Dado que las obsrvaciones están por fecha, asignaremos el valor de **date** a los nombres de las observaciones (filas) del conjunto de datos, y luego la eliminaremos.
* En cuanto a las variables **school_day** y **holiday** las convertiremos a numéricas (asignando 1 para "Y" y 0 para "N").

Así la estructura de datos queda:

```{r convertir a numéricos, echo=FALSE}
# Asignamos la variable date como nombre de las observaciones
rownames(ds_edva_copy) <- ds_edva_copy$date
# Eliminamos date y convertimos a numéricas school_day y holiday
ds_edva_copy <- ds_edva_copy %>% 
  select(-date,-year) %>% 
  mutate(school_day = case_when(
    school_day == "N" ~ 0,
    school_day == "Y" ~ 1,
  ),holiday = case_when(
    holiday == "N" ~ 0,
    holiday == "Y" ~ 1,
  ))
str(ds_edva_copy)
```

Y la vista de las primeras filas del conjunto de datos, así:

```{r encabezados PCA, echo=FALSE}
head(ds_edva_copy)
```

## Implementación de PCA

Procedemos a implementar **PCA** mediante la función *prcomp* con el parámetro scale para normalizar las variables y poder comprarlas entre si. Obtendremos por lo tanto la misma cantidad de componentes principales que la de variables del conjunto de datos (`r ncol(ds_edva_copy)`):

```{r PCA, echo=TRUE, warning=FALSE}
# Implementamos PCA
pca_ds_edva_copy <- prcomp(ds_edva_copy, center = TRUE , scale = TRUE)
pca_ds_edva_copy
```

Y seguidamente presentamos un resumen de **PCA** con la desviación estándard, la proporción de la varianza y el acumulado de esta última.

```{r PCA Summary, echo=FALSE, warning=FALSE}
# Hacemos un summary, con lapply que sale en formato de lista y se lee mejor
summary(pca_ds_edva_copy)
```

## Análisis de resultados

Graficamos las dos componentes con mayor preponderancia, **PCA 1** y **PCA 2**, que conjuntamente acumulan aproximadamente un 41% de la proporción de la varianza.

```{r Plot PCA 1 y 2, echo=FALSE, warning=FALSE}
# Graficamos las dos componentes con mayor preponderancia
plot(pca_ds_edva_copy$x[,1], pca_ds_edva_copy$x[,2], 
     main="Correlación entre el primer par de componentes principales", 
     xlab = "PCA 1", ylab = "PCA 2")
```

Seguidamente determinamos autovalores y autovectores para obtener un gráfico de barras para visualizar la variación porcentual por cada componente principal (Bar Scree Plot). 

```{r BarPlot PCA, echo=FALSE, warning=FALSE}
# Autovalores y autovectores
autovectores <- pca_ds_edva_copy$rotation 
autovalores <- pca_ds_edva_copy$sdev * pca_ds_edva_copy$sdev
# Calculo porcentaje explicado
pca_var_pct <- round(autovalores / sum(autovalores)*100, digits = 2)
barplot(pca_var_pct, main = "Bar Scree Plot", xlab = "Componente Principal", ylab = "Variacion Porcentual")
```

Determinamos las correlaciones entre el conjunto de datos original y las componentes principales:

```{r Correl PCA, echo=FALSE, warning=FALSE}
# Determinamos las correlaciones
round(cor(ds_edva_copy, pca_ds_edva_copy$x), digits = 3)
```

Nuevamente graficamos el *Scree Plot*, aunque en esta oportunidad con forma de líneas, con lo cual aplicamos la “Regla del codo” para elegir la cantidad de componentes para reducir el conjunto de datos en el que tan solo bastaría entre 4 o 5. Más de 5 ofrecerían menores rendimientos explicativos.

```{r ScreePlot PCA, echo=FALSE, warning=FALSE}
# Graficamos Scree Plot PCA
screeplot(pca_ds_edva_copy, type = "l", main = "Scree Plot")
```

Finalmente, graficamos para las dos componentes con mayor preponderancia, **PCA 1** y **PCA 2**, donde para las mismas podemos ver en magnitudes vectoriales que tan representadas enstán las variables de las observaciones el conjunto de deatos; y por su dirección y sentido, cuan correlacionadas entre sí (positivamente cuando aproximadamente tienen el mismo sentido, negativamente en el caso opuesto y sin correlación cuando el ángulo entre sí se acerca al del ángulo recto -90°-). 

```{r Autoplot PCA, echo=FALSE, warning=FALSE}
# Graficamos para las dos componentes con mayor preponderancia y variables
autoplot(pca_ds_edva_copy, loadings = TRUE, loadings.label = TRUE, loadings.label.size  = 3)
```

# Anexo

Tabla interactiva del conjunto de datos

```{r tabla interactiva,echo=FALSE, warning=FALSE}
# Creamos una tabla interactiva
datatable(ds_edva_copy, 
          options = list(pageLength = 10), 
          caption = "Conjunto de datos precio diario, demanda y datos meteorológicos en el Estado de Victoria (Australia)  - Tabla Interactiva")
```
